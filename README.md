# Bachelor-thesis
## 论文信息
> ### 标题
> - 中文标题：**基于图像和激光的多模态点云融合与视觉定位**
>- 英文标题：**Multi-modal point cloud fusion and visual localization based on image and laser**

> ### 作者
> - 姓名：陈奕凡
> - 院系：清华大学 自动化系
> - 指导老师：陈宝华 讲师

> ### 摘要  
> 近年来，三维场景重建与定位是计算机视觉领域中重要的研究方向。随着自动驾驶技术与工业机器人技术的不断发展，对于场景重建精度与定位准确度的要求也不断提高。如何利用各种传感器采集到的数据，完成对场景的精确重建与定位，是非常有价值和应用前景的研究方向。  
目前这一领域中存在着许多挑战：在重建方面，使用传统方法对大场景一次性建图会产生漂移误差，同时效率较低，而采用分区域重建的方法又依赖于准确的融合技术；在定位方面，由于光照环境的变化，定位时刻的环境细节特征与地图重建时刻存在差异，在匹配上存在难度；同时，基于传统单目相机的视觉定位的视场较小，有时无法捕捉到足够多的特征进行定位。这些挑战共同限制了建图的精确性与定位的鲁棒性。  
针对以上挑战，本文提出了一种重建与定位流程：首先利用传感器数据，生成场景局部点云，然后对局部点云进行拼接融合，合成整体场景高精度点云，最后利用全景相机实现在场景中的定位。  
本文主要的研究内容包括：  
1.采用了三个平行的局部重建算法：基于视觉的SfM算法、基于激光雷达的LOAM算法与基于图像激光扫描仪的方法，完成对清华园局部场景的重建任务，为针对不同环境的重建任务在设备和算法选择上提供了参考；  
2.提出一种由粗到精的点云配准算法，对局部场景点云进行融合，生成全局高精度点云。该算法融合了传统特征提取与神经网络的方法，能够在不依赖于初始转移矩阵的情况下具有较为鲁棒的配准结果。  
3.提出一种跨模态鲁棒匹配的视觉定位算法，完成了基于先验点云场景中的定位任务。该算法通过将2D-3D匹配问题转换为2D-2D匹配问题，能够在仅使用全景相机，且不预先对场景进行任何布置的情况下实现定位。  


## 编译论文
初次编译可能时间较久

    git clone https://github.com/chenyifanthu/bachelor-thesis.git
    cd bachelor-thesis
    latexmk -f thesis-2017011621.tex


## 答辩报告
见`report-ppt`文件夹，含开题、中期和终期答辩PPT文件。
