% !TeX encoding = UTF-8
% !TeX root = ../thuthesis-example.tex

\chapter{总结与展望}
\label{ch5}
\section{工作总结}
随着智能机器人领域的日趋成熟，基于各类传感器数据对场景进行重建与定位的应用价值也日渐提升。高精度的传感器能够带来高精度的重建结果、高精度的重建结果加上好的算法能够带来高精度的定位，高精度的定位能够指引场景中的机器人更准确地进行操作，可以说这一整套流程是环环相扣的，因此对于建图与定位的研究也是未来的发展趋势。

根据以上背景，本文提出了一种建图与定位的算法流程。该流程首先对场景进行局部建模，得到局部点云信息，然后利用点云融合算法将局部的点云地图融合为高精度的全局地图，完成建图工作；随后提出了一种视觉定位算法，在输入已知场景点云地图与某一位置的全景图像的条件下，能够输出图像在场景中的绝对位置。

本文的局部点云构建模块采用了三个平行算法，分别是基于单目视觉的SfM算法、基于激光雷达的LOAM算法以及基于图像激光全景扫描仪的方法，这些算法都能够得到场景的局部点云地图，但是其精度与采集成本各不相同，在实际场景中可以根据实际情况来对方法进行选择。同时，本文也在大礼堂门口分别采用这三种方式进行了数据采集与重建实验并进行了对比。

本文的点云融合模块采用了一个由粗到精的配准框架。在点云的粗匹配阶段，先利用FPFH算法求取点云中每个点的特征描述子并构建kd-tree以便搜索，然后利用RANSAC方法估计两个点云之间的转移矩阵，得到点对匹配关系。将得到的匹配关系输入3DRegNet网络，消除其中的噪声，即错误匹配对，得到了更准确的匹配对，进而得到了精细化的点云匹配结果。本文在自己采集的数据集上进行了双点云与多点云的融合实验，结果均证明了此方法在点云融合上式有效的。

本文的定位模块解决了在3D场景中利用单帧2D全景图像进行定位的问题。将2D-3D匹配问题转化成了2D-2D匹配问题，其中涉及到点云平面化、全景图像畸变校正的问题，并利用SOSNet网络鲁棒地提取与匹配两帧图像的特征点。本文在室外与室内环境分别进行了单帧图像定位于连续帧视频的定位实验，结果也证明了本文提到的定位算法是有效可行的。

\section{工作展望}

本研究通过传统方法与深度学习的方法进行了融合，完成了三维建图与定位的任务，提出了一套可行的算法流程。但其中有一些值得改进的地方，主要包括以下几点：
\begin{enumerate}
	\item 在局部建图部分对于多传感器的融合。在第2章中，本文分析了不同传感器在采集成本与重建精度上的利弊。因此在未来，可以考虑这几个方向的融合研究，例如将单目相机与激光扫描仪结合，分别弥补两者重建精度不准确以及采集成本高的缺点，同时改善局部重建的效果。
	\item 点云融合的鲁棒性。在点云融合中，本文结合了传统算法与深度学习的算法，但通过实验发现，传统方法部分有的时候并不能给出一个较好的粗对齐结果与点对关系估计，有的时候也会含有大量的错误值，并且粗对齐的结果依赖于过程当中一部分参数的选取，这使得精匹配后的效果也不太理想。因此可以考虑继续探索最新的点云配准网络，采用纯学习的方法来获得更鲁棒的点云融合结果。
	\item 点云融合过程中对于RGB信息的利用。本文提到的点云融合框架只利用了点云中的RGB信息，但事实上在使用激光雷达扫描仪进行局部数据采集的时候是能够得到点的颜色信息的，这一信息在之后的定位环节中得以应用但是在重建上没有体现。因此可以考虑如何将这一信息加入已有的框架中，提高重建的准确率。
	\item 定位算法的效率。在定位中本文采用了SOSNet进行特征匹配，这虽然能提升匹配的鲁棒性，但是带来的问题是算法耗时较长，并且依赖于移动设备的计算能力。因此在未来可以考虑鲁棒性与实时性之间的平衡。
\end{enumerate}















